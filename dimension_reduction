import numpy as np
import networkx as nx
import pickle as pk
from numpy import linalg as LA
from sklearn.decomposition import PCA
import scipy.stats.mstats
from sklearn.svm import SVC
from collections import Counter
from sklearn.cluster import SpectralClustering
from sklearn.metrics.cluster import adjusted_rand_score


def parse_graph_data(graph_name='../../../ENZYMES/enzymes.graph'):
    if graph_name == 'nci1.graph':
        maxval = 37
        n_classes = 2
    elif graph_name == 'nci109.graph':
        maxval = 38
        n_classes = 2
    elif graph_name == 'mutag.graph':
        maxval = 7
        n_classes = 2
    elif graph_name == 'ptc.graph':
        maxval = 22
        n_classes = 2
    elif graph_name == '../../../ENZYMES/enzymes.graph':
        maxval = 3
        n_classes = 6
    
    with open(graph_name,'rb') as f:
        new_f = pk._Unpickler(f)
        new_f.encoding = 'latin1'
        raw = new_f.load()
        
        n_graphs = len(raw['graph'])
        
        A = []
        rX = []
        Y = []
        
        for i in range(n_graphs):
            # Set label
            class_label = raw['labels'][i]
            
            Y.append(class_label)
            
            # Parse graph
            G = raw['graph'][i]
            
            n_nodes = len(G)
            
            a = np.zeros((n_nodes, n_nodes), dtype='float32')
            x = np.zeros((n_nodes, maxval), dtype='float32')
            
            for node, meta in G.items():
                label = meta['label'][0] - 1
                x[node, label] = 1
                for neighbor in meta['neighbors']:
                    a[node, neighbor] = 1
            
            A.append(a)
            rX.append(x)

    return A, rX, Y


def lazy_random_walk(A):
    #if d == 0, P = 0
    #P_array = []
    d = A.sum(0)
    P_t = A/d
    P_t[np.isnan(P_t)] = 0
    P = 1/2*(np.identity(P_t.shape[0])+P_t)
    #for i in range(0,t,2):
    #for i in range(t+1):
    #for i in [0]:
    #P_array.append(LA.matrix_power(P,i))
    #return P_array,P
    return P



def graph_wavelet(P):
    psi = []
    #for d1 in range(1,t,2):
    #for d1 in range(1,t+1):
    for d1 in [1,2,4,8,16]:
        W_d1 = LA.matrix_power(P,d1) - LA.matrix_power(P,2*d1)
        psi.append(W_d1)
    return psi



def zero_order_feature(ro,f):
    F0 = []
    for i in [1,2,3,4]:
        F0.append(np.sum(np.power(np.abs(ro),i),0))
    F0 = np.array(F0).reshape(-1,1)
    return F0



def first_order_feature(u,f):
    F1  = []
    for i in [1,2,3,4]:
        F1.append(np.sum(np.power(u,i),1))
    F1 = np.array(F1).reshape(-1,1)
    #F = []
    #F.append(np.sum(np.matmul(P,u[0]),1))
    #for i in range(1,t):
    #F = np.concatenate((F,np.sum(np.matmul(P,u[i]))),1)
    return F1



def selected_second_order_feature(W,u,f):
    u1 = np.einsum('ij,ajt ->ait',W[1],u[0:1])
    for i in range(2,len(W)):
        u1 = np.concatenate((u1,np.einsum('ij,ajt ->ait',W[i],u[0:i])),0)
    u1 = np.abs(u1)
    F2 = []
    for i in [1,2,3,4]:
        F2.append(np.sum(np.power(u1,i),1))
    F2 = np.array(F2).reshape(-1,1)
    #F2.append(np.sum(np.einsum('ij,ajt ->ait',W[i],u[0:i]),1).reshape(len(u[0:i])*F,1))
    #F2 = np.sum(np.einsum('ijk,akt ->iajt',P,F1),2).reshape(len(P)*len(F1)*F,1)
    #F2 = np.array(F2).reshape()
    return F2





def generate_mol_feature(A,f,ro):
    #with zero order, first order and second order features
    #shall consider only zero and first order features
    P = lazy_random_walk(A)
    W = graph_wavelet(P)
    u = np.abs(np.matmul(W,ro))
    
    F0 = zero_order_feature(ro,f)
    F1 = first_order_feature(u,f)
    #F2 = second_order_feature(W,u,P[0],t,F)
    F2 = selected_second_order_feature(W,u,f)
    #F3 = selected_third_order_feature(W,u,P[0],t,F)
    F = np.concatenate((F0,F1),axis=0)
    F = np.concatenate((F,F2),axis=0)
    #F = np.concatenate((F1,F2),axis=0)
    #F = np.concatenate((F,F3),axis=0)
    return F
print('feature is [1,2,3,4]+[1,2,4,8,16]')

print('start reading file')
A, rX, Y = parse_graph_data(graph_name='../../../ENZYMES/enzymes.graph')
print('finish reading')

print('start feature generation')
feature = []

maxvalue = 3
for i in range(len(A)):
    if i%200 == 0:
        print(i)
    #F = generate_mol_feature(A[i],t,maxvalue,rX[i])
    feature.append(generate_mol_feature(A[i],maxvalue,rX[i]))
print('finish feature generation')

feature = np.reshape(feature,(len(feature),feature[0].shape[0]))


print('feature shape',feature.shape)


#normalize feature
norm_feature = np.sum(np.power(feature,2),axis=0)



zero_list = []
for i in range(len(norm_feature)):
    if norm_feature[i] == 0:
        zero_list.append(i)



for i in reversed(zero_list):
    feature = np.concatenate((feature[:,0:i],feature[:,i+1:]),1)


print('feature shape',feature.shape)


feature_z = scipy.stats.mstats.zscore(feature,0)



print('feature z shape',feature_z.shape)

clustering = SpectralClustering(n_clusters=6,assign_labels="kmeans",random_state=0).fit(feature_z)
clustering_result = clustering.labels_
score = adjusted_rand_score(Y,clustering_result)
print('rand index score is',score)



class1 = []
class2 = []
class3 = []
class4 = []
class5 = []
class6 = []
for i in range(len(Y)):
    if Y[i] == 1:
        class1.append(feature_z[i])
    elif Y[i] == 2:
        class2.append(feature_z[i])
    elif Y[i] == 3:
        class3.append(feature_z[i])
    elif Y[i] == 4:
        class4.append(feature_z[i])
    elif Y[i] == 5:
        class5.append(feature_z[i])
    elif Y[i] == 6:
        class6.append(feature_z[i])

print('class1 size',len(class1))
print('class2 size',len(class2))
print('class3 size',len(class3))
print('class4 size',len(class4))
print('class5 size',len(class5))
print('class6 size',len(class6))

pca0 = PCA(n_components=0.9,svd_solver = 'full')
pca0.fit(feature_z)

pca_feature = pca0.fit_transform(feature_z)

print('pca all variance covered',pca0.explained_variance_ratio_)
print('pca all n components',pca0.n_components_)

pca1 = PCA(n_components=0.9,svd_solver = 'full')
pca1.fit(class1)
components1 = pca1.components_

print('pca class1 variance covered',pca1.explained_variance_ratio_)
print('pca class1 n components',pca1.n_components_)

pca2 = PCA(n_components=0.9,svd_solver = 'full')
pca2.fit(class2)
components2 = pca2.components_

print('pca class2 variance covered',pca2.explained_variance_ratio_)
print('pca class2 n components',pca2.n_components_) 

pca3 = PCA(n_components=0.9,svd_solver = 'full')
pca3.fit(class3)
components3 = pca3.components_
print('pca class3 variance covered',pca3.explained_variance_ratio_)
print('pca class3 n components',pca3.n_components_)

pca4 = PCA(n_components=0.9,svd_solver = 'full')
pca4.fit(class4)
components4 = pca4.components_
print('pca class4 variance covered',pca4.explained_variance_ratio_)
print('pca class4 n components',pca4.n_components_)

pca5 = PCA(n_components=0.9,svd_solver = 'full')
pca5.fit(class5)
components5 = pca5.components_
print('pca class5 variance covered',pca5.explained_variance_ratio_)
print('pca class5 n components',pca5.n_components_)

pca6 = PCA(n_components=0.9,svd_solver = 'full')
pca6.fit(class6)
components6 = pca6.components_
print('pca class6 variance covered',pca6.explained_variance_ratio_)
print('pca class6 n components',pca6.n_components_)

loss11 = 0
loss12 = 0
loss13 = 0
loss14 = 0
loss15 = 0
loss16 = 0

count1 = 0
count2 = 0
count3 = 0
count4 = 0
count5 = 0
count6 = 0

count1_ = 0
count2_ = 0
count3_ = 0
count4_ = 0
count5_ = 0
count6_ = 0

for i in range(len(class1)):
    Px1 = sum(np.multiply(np.matmul(components1,class1[i]),np.transpose(components1)).transpose())
    Px2 = sum(np.multiply(np.matmul(components2,class1[i]),np.transpose(components2)).transpose())
    Px3 = sum(np.multiply(np.matmul(components3,class1[i]),np.transpose(components3)).transpose())
    Px4 = sum(np.multiply(np.matmul(components4,class1[i]),np.transpose(components4)).transpose())
    Px5 = sum(np.multiply(np.matmul(components5,class1[i]),np.transpose(components5)).transpose())
    Px6 = sum(np.multiply(np.matmul(components6,class1[i]),np.transpose(components6)).transpose())
    
    temp1 = sum((class1[i]-Px1)**2)
    temp2 = sum((class1[i]-Px2)**2)
    temp3 = sum((class1[i]-Px3)**2)
    temp4 = sum((class1[i]-Px4)**2)
    temp5 = sum((class1[i]-Px5)**2)
    temp6 = sum((class1[i]-Px6)**2)
    
    pool = sorted([temp1,temp2,temp3,temp4,temp5,temp6])
    if pool[0] == temp1:
        count1 = count1+1
    if pool[1] == temp1:
        count1_ = count1_+1
    
    loss11 = temp1+loss11
    loss12 = temp2+loss12
    loss13 = temp3+loss13
    loss14 = temp4+loss14
    loss15 = temp5+loss15
    loss16 = temp6+loss16

dist11 = loss11/len(class1)
dist12 = loss12/len(class1)
dist13 = loss13/len(class1)
dist14 = loss14/len(class1)
dist15 = loss15/len(class1)
dist16 = loss16/len(class1)

print('dist11 is',dist11)
print('dist12 is',dist12)
print('dist13 is',dist13)
print('dist14 is',dist14)
print('dist15 is',dist15)
print('dist16 is',dist16)
print('count1 is',count1)
print('count1_ is',count1_)

loss21 = 0
loss22 = 0
loss23 = 0
loss24 = 0
loss25 = 0
loss26 = 0

for i in range(len(class2)):
    Px1 = sum(np.multiply(np.matmul(components1,class2[i]),np.transpose(components1)).transpose())
    Px2 = sum(np.multiply(np.matmul(components2,class2[i]),np.transpose(components2)).transpose())
    Px3 = sum(np.multiply(np.matmul(components3,class2[i]),np.transpose(components3)).transpose())
    Px4 = sum(np.multiply(np.matmul(components4,class2[i]),np.transpose(components4)).transpose())
    Px5 = sum(np.multiply(np.matmul(components5,class2[i]),np.transpose(components5)).transpose())
    Px6 = sum(np.multiply(np.matmul(components6,class2[i]),np.transpose(components6)).transpose())
    
    temp1 = sum((class2[i]-Px1)**2)
    temp2 = sum((class2[i]-Px2)**2)
    temp3 = sum((class2[i]-Px3)**2)
    temp4 = sum((class2[i]-Px4)**2)
    temp5 = sum((class2[i]-Px5)**2)
    temp6 = sum((class2[i]-Px6)**2)
    
    pool = sorted([temp1,temp2,temp3,temp4,temp5,temp6])
    if pool[0] == temp2:
        count2 = count2+1
    if pool[1] == temp2:
        count2_ = count2_+1
    
    loss21 = temp1+loss21
    loss22 = temp2+loss22
    loss23 = temp3+loss23
    loss24 = temp4+loss24
    loss25 = temp5+loss25
    loss26 = temp6+loss26

dist21 = loss21/len(class2)
dist22 = loss22/len(class2)
dist23 = loss23/len(class2)
dist24 = loss24/len(class2)
dist25 = loss25/len(class2)
dist26 = loss26/len(class2)

print('dist21 is',dist21)
print('dist22 is',dist22)
print('dist23 is',dist23)
print('dist24 is',dist24)
print('dist25 is',dist25)
print('dist26 is',dist26)
print('count2 is',count2)
print('count2_ is',count2_)

loss31 = 0
loss32 = 0
loss33 = 0
loss34 = 0
loss35 = 0
loss36 = 0

for i in range(len(class3)):
    Px1 = sum(np.multiply(np.matmul(components1,class3[i]),np.transpose(components1)).transpose())
    Px2 = sum(np.multiply(np.matmul(components2,class3[i]),np.transpose(components2)).transpose())
    Px3 = sum(np.multiply(np.matmul(components3,class3[i]),np.transpose(components3)).transpose())
    Px4 = sum(np.multiply(np.matmul(components4,class3[i]),np.transpose(components4)).transpose())
    Px5 = sum(np.multiply(np.matmul(components5,class3[i]),np.transpose(components5)).transpose())
    Px6 = sum(np.multiply(np.matmul(components6,class3[i]),np.transpose(components6)).transpose())
    
    temp1 = sum((class3[i]-Px1)**2)
    temp2 = sum((class3[i]-Px2)**2)
    temp3 = sum((class3[i]-Px3)**2)
    temp4 = sum((class3[i]-Px4)**2)
    temp5 = sum((class3[i]-Px5)**2)
    temp6 = sum((class3[i]-Px6)**2)
    
    pool = sorted([temp1,temp2,temp3,temp4,temp5,temp6])
    if pool[0] == temp3:
        count3 = count3+1
    if pool[1] == temp3:
        count3_ = count3_+1
    
    loss31 = temp1+loss31
    loss32 = temp2+loss32
    loss33 = temp3+loss33
    loss34 = temp4+loss34
    loss35 = temp5+loss35
    loss36 = temp6+loss36

dist31 = loss31/len(class3)
dist32 = loss32/len(class3)
dist33 = loss33/len(class3)
dist34 = loss34/len(class3)
dist35 = loss35/len(class3)
dist36 = loss36/len(class3)

print('dist31 is',dist31)
print('dist32 is',dist32)
print('dist33 is',dist33)
print('dist34 is',dist34)
print('dist35 is',dist35)
print('dist36 is',dist36)
print('count3 is',count3)
print('count3_ is',count3_)

loss41 = 0
loss42 = 0
loss43 = 0
loss44 = 0
loss45 = 0
loss46 = 0

for i in range(len(class4)):
    Px1 = sum(np.multiply(np.matmul(components1,class4[i]),np.transpose(components1)).transpose())
    Px2 = sum(np.multiply(np.matmul(components2,class4[i]),np.transpose(components2)).transpose())
    Px3 = sum(np.multiply(np.matmul(components3,class4[i]),np.transpose(components3)).transpose())
    Px4 = sum(np.multiply(np.matmul(components4,class4[i]),np.transpose(components4)).transpose())
    Px5 = sum(np.multiply(np.matmul(components5,class4[i]),np.transpose(components5)).transpose())
    Px6 = sum(np.multiply(np.matmul(components6,class4[i]),np.transpose(components6)).transpose())
    
    temp1 = sum((class4[i]-Px1)**2)
    temp2 = sum((class4[i]-Px2)**2)
    temp3 = sum((class4[i]-Px3)**2)
    temp4 = sum((class4[i]-Px4)**2)
    temp5 = sum((class4[i]-Px5)**2)
    temp6 = sum((class4[i]-Px6)**2)
    
    pool = sorted([temp1,temp2,temp3,temp4,temp5,temp6])
    if pool[0] == temp4:
        count4 = count4+1
    if pool[1] == temp4:
        count4_ = count4_+1
    
    loss41 = temp1+loss41
    loss42 = temp2+loss42
    loss43 = temp3+loss43
    loss44 = temp4+loss44
    loss45 = temp5+loss45
    loss46 = temp6+loss46

dist41 = loss41/len(class4)
dist42 = loss42/len(class4)
dist43 = loss43/len(class4)
dist44 = loss44/len(class4)
dist45 = loss45/len(class4)
dist46 = loss46/len(class4)

print('dist41 is',dist41)
print('dist42 is',dist42)
print('dist43 is',dist43)
print('dist44 is',dist44)
print('dist45 is',dist45)
print('dist46 is',dist46)
print('count4 is',count4)
print('count4_ is',count4_)

loss51 = 0
loss52 = 0
loss53 = 0
loss54 = 0
loss55 = 0
loss56 = 0

for i in range(len(class5)):
    Px1 = sum(np.multiply(np.matmul(components1,class5[i]),np.transpose(components1)).transpose())
    Px2 = sum(np.multiply(np.matmul(components2,class5[i]),np.transpose(components2)).transpose())
    Px3 = sum(np.multiply(np.matmul(components3,class5[i]),np.transpose(components3)).transpose())
    Px4 = sum(np.multiply(np.matmul(components4,class5[i]),np.transpose(components4)).transpose())
    Px5 = sum(np.multiply(np.matmul(components5,class5[i]),np.transpose(components5)).transpose())
    Px6 = sum(np.multiply(np.matmul(components6,class5[i]),np.transpose(components6)).transpose())
    
    temp1 = sum((class5[i]-Px1)**2)
    temp2 = sum((class5[i]-Px2)**2)
    temp3 = sum((class5[i]-Px3)**2)
    temp4 = sum((class5[i]-Px4)**2)
    temp5 = sum((class5[i]-Px5)**2)
    temp6 = sum((class5[i]-Px6)**2)
    
    pool = sorted([temp1,temp2,temp3,temp4,temp5,temp6])
    if pool[0] == temp5:
        count5 = count5+1
    if pool[1] == temp5:
        count5_ = count5_+1
    
    loss51 = temp1+loss51
    loss52 = temp2+loss52
    loss53 = temp3+loss53
    loss54 = temp4+loss54
    loss55 = temp5+loss55
    loss56 = temp6+loss56

dist51 = loss51/len(class5)
dist52 = loss52/len(class5)
dist53 = loss53/len(class5)
dist54 = loss54/len(class5)
dist55 = loss55/len(class5)
dist56 = loss56/len(class5)

print('dist51 is',dist51)
print('dist52 is',dist52)
print('dist53 is',dist53)
print('dist54 is',dist54)
print('dist55 is',dist55)
print('dist56 is',dist56)
print('count5 is',count5)
print('count5_ is',count5_)


loss61 = 0
loss62 = 0
loss63 = 0
loss64 = 0
loss65 = 0
loss66 = 0

for i in range(len(class6)):
    Px1 = sum(np.multiply(np.matmul(components1,class6[i]),np.transpose(components1)).transpose())
    Px2 = sum(np.multiply(np.matmul(components2,class6[i]),np.transpose(components2)).transpose())
    Px3 = sum(np.multiply(np.matmul(components3,class6[i]),np.transpose(components3)).transpose())
    Px4 = sum(np.multiply(np.matmul(components4,class6[i]),np.transpose(components4)).transpose())
    Px5 = sum(np.multiply(np.matmul(components5,class6[i]),np.transpose(components5)).transpose())
    Px6 = sum(np.multiply(np.matmul(components6,class6[i]),np.transpose(components6)).transpose())
    
    temp1 = sum((class6[i]-Px1)**2)
    temp2 = sum((class6[i]-Px2)**2)
    temp3 = sum((class6[i]-Px3)**2)
    temp4 = sum((class6[i]-Px4)**2)
    temp5 = sum((class6[i]-Px5)**2)
    temp6 = sum((class6[i]-Px6)**2)
    
    pool = sorted([temp1,temp2,temp3,temp4,temp5,temp6])
    if pool[0] == temp6:
        count6 = count6+1
    if pool[1] == temp5:
        count6_ = count6_+1
    
    loss61 = temp1+loss61
    loss62 = temp2+loss62
    loss63 = temp3+loss63
    loss64 = temp4+loss64
    loss65 = temp5+loss65
    loss66 = temp6+loss66

dist61 = loss61/len(class6)
dist62 = loss62/len(class6)
dist63 = loss63/len(class6)
dist64 = loss64/len(class6)
dist65 = loss65/len(class6)
dist66 = loss66/len(class6)

print('dist61 is',dist61)
print('dist62 is',dist62)
print('dist63 is',dist63)
print('dist64 is',dist64)
print('dist65 is',dist65)
print('dist66 is',dist66)
print('count6 is',count5)
print('count6_ is',count5_)

G_pool = [0.00001,0.0001,0.001, 0.01, 0.1]



C_pool = [0.01, 0.1, 1, 10,25,50,100,1000]



def cross_validate(split_size,train_all_feature,train_all_Y,test_feature,test_Y,outter_loop,G_pool,C_pool):
    results = []
    train_idx,val_idx = Kfold(len(train_all_feature),split_size)
    prediction = []
    
    #train_all_feature = np.reshape(train_all_feature,(len(train_all_feature),len(train_all_feature[0])))
    #train_all_Y = np.reshape(train_all_Y,(len(train_all_Y),len(train_all_Y[0])))
    
    test_feature = np.reshape(test_feature,(len(test_feature),len(test_feature[0])))
    
    
    for k in range(split_size):
        train_feature = [train_all_feature[i] for i in train_idx[k]]
        train_Y = [train_all_Y[i] for i in train_idx[k]]
        val_feature = [train_all_feature[i] for i in val_idx[k]]
        val_Y = [train_all_Y[i] for i in val_idx[k]]
        
        
        train_feature = np.reshape(train_feature,(len(train_feature),len(train_feature[0])))
        val_feature = np.reshape(val_feature,(len(val_feature),len(val_feature[0])))
        
        
        print('outter_loop',outter_loop)
        print('inner_loop',k,'start')
        
        #epoch_result = []
        #for epoch in epoch_list:
        print('start best para search')
        #run_train(session, train_feature, train_Y, epoch)
        #epoch_result.append(session.run(accuracy, feed_dict={fea: val_feature, clas: val_Y}))
        #best_regu,best_W,best_epoch = run_train(train_feature,train_Y,starting_epoch,regularizer_pool,W_pool,val_feature,val_Y,learning_rate)
        test_score,preds,best_c,best_g = run_train(train_feature,train_Y,G_pool,C_pool,val_feature,val_Y,test_feature,test_Y)
        #print('test score is', test_score)
        #print('start best para training/test')
        #score,preds = run_test(train_all_feature,train_all_Y,test_feature,test_Y,best_regu,best_W,best_epoch,learning_rate)
        #print('finished best epoch training')
        results.append(test_score)
        prediction.append(preds)
        #print(preds)
        print('this run accuracy is', results[-1])
        print('inner_loop',k,'ends')
        print('best c is',best_c)
        print('best g is',best_g)
    #print(prediction)
    #prediction = np.reshape(9,len(prediction[0]))
    
    prediction = np.array(prediction)
    #print(prediction.shape)
    pre = []
    for i in range(prediction.shape[1]):
        pre.append(Counter(prediction[:,i]).most_common(1)[0][0])
    test_acc = np.mean(np.equal(pre,test_Y))
    return (results,test_acc)

#def run_test(train_all_feature,train_all_Y,test_feature,test_Y,best_regu,best_W,best_epoch,learning_rate):
#    model = geometric_scattering_classifier(best_W,best_regu,learning_rate)
#    model.fit(train_all_feature,train_all_Y,epochs=best_epoch,batch_size=64,shuffle=False)
#    loss,score = model.evaluate(test_feature,test_Y)
#    preds = model.predict(test_feature)
#    return (score,preds)


def run_train(train_feature,train_Y,G_pool,C_pool,val_feature,val_Y,test_feature,test_Y):
    temp = 0
    for c in C_pool:
        for g in G_pool:
            model = SVC(kernel='rbf',C=c,gamma=g)
            model.fit(train_feature,train_Y)
            score = model.score(val_feature,val_Y)
            print('c is',c)
            print('g is',g)
            print('this run validation score is',score)
            if score >temp:
                temp =score
                test_score = model.score(test_feature,test_Y)
                preds = model.predict(test_feature)
                best_c = c
                best_g = g
    return (test_score,preds,best_c,best_g)
#def write_to_file(index):
#with open('shuffle_index_0.txt','w') as file:
#for i in index:
#file.write(str(i))
#file.write('\t')

def shuffled(index,norm_feature,Y):
    new_feature = []
    new_Y = []
    for i in index:
        new_feature.append(norm_feature[i])
        new_Y.append(Y[i])
    return (new_feature,new_Y)



def Kfold(length,fold):
    size = np.arange(length).tolist()
    train_index = []
    val_index = []
    rest = length % fold
    fold_size = int(length/fold)
    temp_fold_size = fold_size
    for i in range(fold):
        temp_train = []
        temp_val = []
        if rest>0:
            temp_fold_size = fold_size+1
            rest = rest -1
            temp_val = size[i*temp_fold_size:+i*temp_fold_size+temp_fold_size]
            temp_train = size[0:i*temp_fold_size] + size[i*temp_fold_size+temp_fold_size:]
        else:
            temp_val = size[(length % fold)*temp_fold_size+(i-(length % fold))*fold_size
                            :(length % fold)*temp_fold_size+(i-(length % fold))*fold_size+fold_size]
            temp_train = size[0:(length % fold)*temp_fold_size+(i-(length % fold))*fold_size] + size[(length % fold)*temp_fold_size+(i-(length % fold))*fold_size+fold_size:]
        train_index.append(temp_train)
        val_index.append(temp_val)
    return (train_index,val_index)



index = np.arange(len(rX))
np.random.shuffle(index)
#write_to_file(index)
n_splits = 10
shuffled_feature,shuffled_Y = shuffled(index,pca_feature,Y)
train_id,test_id = Kfold(len(shuffled_feature),n_splits)
outter_loop = 0
test_accuracy = []
for k in range(n_splits):
    
    print('begin cross validation')
    outter_loop = outter_loop +1
    print('outter loop',outter_loop,'start')
    
    train_all_feature = [shuffled_feature[i] for i in train_id[k]]
    train_all_Y = [shuffled_Y[i] for i in train_id[k]]
    test_feature = [shuffled_feature[i] for i in test_id[k]]
    test_Y = [shuffled_Y[i] for i in test_id[k]]
    
    result,prediction_acc = cross_validate(9,train_all_feature,train_all_Y,test_feature,test_Y,outter_loop,G_pool,C_pool)
    #run_train(session, train_all_feature, train_all_Y)
    print("Cross-validation result: %s" % result)
    print('prediction accuracy',prediction_acc)
    test_accuracy.append(prediction_acc)
    print('outter loop',outter_loop,'ends')
#print("Test accuracy: %f" % session.run(accuracy, feed_dict={fea: test_feature, clas: test_Y}))
print(test_accuracy)
print('mean accuracy is ', np.mean(test_accuracy))
print('std is', np.std(test_accuracy))

